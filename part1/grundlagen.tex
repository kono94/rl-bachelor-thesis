Bei dem Bestärkten Lernen (\textit{Reinforcement Learning}) interagiert ein Softwareagent (\textit{Agent}) mit seiner Umwelt (\textit{Environment}), die wiederum nach jeder Aktion (\textit{Action}) Feedback an den Agenten zurückgibt. Dieses Feedback wird als Belohnung (\textit{Reward}) bezeichnet, einem numerischen Wert, der sowohl positiv als auch negativ sein kann. Der Agent beobachtet zudem den Folgezustand (\textit{State}) in dem sich die Umwelt nach der vorigen Aktion befindet, um so seine nächste Entscheidung treffen zu können. Ziel des Agenten ist es eine Strategie (\textit{Policy}) zu entwickeln, so dass die Folge seiner Entscheidungen die Summe aller Belohnungen maximiert.